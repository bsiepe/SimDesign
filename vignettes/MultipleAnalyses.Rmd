---
title: "Multiple Analysis Functions"
author: "Phil Chalmers"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: false
    number_sections: true 
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
vignette: >
  %\VignetteIndexEntry{Catching errors}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r nomessages, echo = FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  fig.height = 5,
  fig.width = 5
)
options(digits=4)
par(mar=c(3,3,1,1)+.1)
```

This vignette demonstrates one of the newer features in the `SimDesign` package pertaining to multiple analysis function definitions. The purpose of providing multiple analysis functions is to 

1) Remove the less readable if-then-else combinations that sometimes appear when writing simulation code where some analysis functions are not intended to be used on a given dataset, 
2) Provide better automatic naming of the results across independent analyses subroutines, and to
3) Create a more modular approach to isolating the analysis functions for the purpose of redistribution or reusing the analysis in related projects

Functionality speaking this type of organization does not change much, as so for that reason the coding style could generally be considered optional. However, if any of the above points resonate well then following the details of this vignette may prove useful. 

# Description of structure

The usual workflow with `SimDesign` requires first calling `SimFunctions()` to generate a working template. In the context of multiple analysis functions, however, users should pass the number of analysis functions they believe they will need in their simulation by way of the `nanalyse` argument (e.g., if analyzing a $t$-test setup to compare the Welch versus independent samples t-test, then two analysis functions should be used). This creates the following output:


```{r}
SimDesign::SimFunctions(nanalyse = 2)
```

Notice in this case that there were two `Analyse()` definitions constructed, and when passed to `runSimulation()` these are organized as a named list. The names of the list will ultimately be pretended to the names of the analysis objects so that there is no ambiguity in the outputted information. By default users will see output such as `analyse1.some_statistic`, `analyse1.some_other_statistic`, ..., `analyse2.some_other_statistic`, and so on. Note that all the rules about objects and object naming from the typical single Analyse function still apply and are properly checked internally for suitable names and consistency. 


# An example

The following code is [adopted from the Wiki](http://philchalmers.github.io/SimDesign/html/03-Parameter_recovery_simulation.html), and so details about the simulation should be obtained from that source. 

```{r}
library(SimDesign)
# SimFunctions(nanalyse=2)

sample_sizes <- c(250, 500, 1000)
nitems <- c(10, 20)
Design <- createDesign(sample_size = sample_sizes, 
                       nitems = nitems)

# create list of additional parameters which are fixed across conditions
set.seed(1)
pars_10 <- rbind(a = round(rlnorm(10, .3, .5)/1.702, 2),
                 d = round(rnorm(10, 0, .5)/1.702, 2))
pars_20 <- rbind(a = round(rlnorm(20, .3, .5)/1.702, 2),
                 d = round(rnorm(20, 0, .5)/1.702, 2))
pars <- list(ten=pars_10, twenty=pars_20)

P_logit <- function(a, d, Theta) exp(a * Theta + d) / (1 + exp(a * Theta + d))
P_ogive <- function(a, d, Theta) pnorm(a * Theta + d)
```

```{r}
Generate <- function(condition, fixed_objects = NULL) {

    N <- condition$sample_size
    nitems <- condition$nitems
    nitems_name <- ifelse(nitems == 10, 'ten', 'twenty')

    #extract objects from fixed_objects
    a <- fixed_objects[[nitems_name]]['a', ]
    d <- fixed_objects[[nitems_name]]['d', ]

    dat <- matrix(NA, N, nitems)
    colnames(dat) <- paste0('item_', 1:nitems)
    Theta <- rnorm(N)
    for(j in 1:nitems){
        p <- P_ogive(a[j], d[j], Theta)
        for(i in 1:N)
            dat[i,j] <- sample(c(1,0), 1, prob = c(p[i], 1 - p[i]))
    }
    as.data.frame(dat) #data.frame works nicer with lavaan
}

Analyse1 <- function(condition, dat, fixed_objects = NULL) {
    mod <- mirt(dat, 1L, verbose=FALSE)
    if(!extract.mirt(mod, 'converged')) stop('mirt did not converge')
    cfs <- coef(mod, simplify = TRUE, digits = Inf)
    FIML_as <- cfs$items[,1L] / 1.702
    
    ret <- c(as=unname(FIML_as))
    ret
}

Analyse2 <- function(condition, dat, fixed_objects = NULL) {
    nitems <- condition$nitems
    lavmod <- paste0('F =~ ', paste0('NA*', colnames(dat)[1L], ' + '),
                     paste0(colnames(dat)[-1L], collapse = ' + '),
                     '\nF ~~ 1*F')
    lmod <- sem(lavmod, dat, ordered = colnames(dat))
    if(!lavInspect(lmod, 'converged')) stop('lavaan did not converge')
    cfs2 <- coef(lmod)
    DWLS_alpha <- cfs2[1L:nitems]
    const <- sqrt(1 - DWLS_alpha^2)
    DWLS_as <- DWLS_alpha / const

    ret <- c(as=unname(DWLS_as))
    ret
}

Summarise <- function(condition, results, fixed_objects = NULL) {
    nitems <- condition$nitems
    nitems_name <- ifelse(nitems == 10, 'ten', 'twenty')

    #extract objects from fixed_objects
    a <- fixed_objects[[nitems_name]]['a', ]
    pop <- c(a, a)

    obt_bias <- bias(results, pop)
    obt_RMSE <- RMSE(results, pop)
    ret <- c(bias=obt_bias, RMSE=obt_RMSE)
    ret
}
```

```{r eval=FALSE}
res <- runSimulation(Design, replications=100, verbose=FALSE, 
                     parallel=TRUE, generate=Generate, 
                     analyse=list(FIML=Analyse1, DWLS=Analyse2), 
                     summarise=Summarise, filename = 'mirt_lavaan',
                     packages=c('mirt', 'lavaan'), fixed_objects=pars)
res
```

```{r echo=FALSE}
res <- readRDS("mirt_lavaan.rds")
res
```

In this particular formulation the `mirt` and `lavaan` package analyses have been completely
isolated into their own respective functions, and in principle could therefore be analyzed 
independently in future simulation studies. 


# `AnalyseIf()`

In situations where specific analysis functions defining in the `analyse` list should only be applied in certain situations but not others, users can specify an `AnalyseIf()` logical definition at the beginning of their respective functions. This logical ensures the data generation conditions are suitable for the analysis function to be investigated, otherwise it is skipped over in the generate-analyse-summarise workflow. 

As a continuation from above, say that an investigator was also interested in recovering the slope parameters of a factor analysis model where the observed indicator variable were continuous rather than discrete. 

```{r}
Design <- createDesign(sample_size = sample_sizes, 
                       nitems = nitems, 
                       indicators = c('discrete', 'continuous'))
Design
```

In this case, `lavaan` could be used as it supports such indicator types, however `mirt` cannot. So, to ensure that only the analysis function pertaining to `lavaan` is used one could include the following replacement definition that used `mirt` above.

```{r}
Analyse1 <- function(condition, dat, fixed_objects = NULL) {
    AnalyseIf(condition$indicators == 'discrete')
    # alternatively: 
    #   AnalyseIf(indicators == 'discrete', condition)
    mod <- mirt(dat, 1L, verbose=FALSE)
    if(!extract.mirt(mod, 'converged')) stop('mirt did not converge')
    cfs <- coef(mod, simplify = TRUE, digits = Inf)
    FIML_as <- cfs$items[,1L] / 1.702
    
    ret <- c(as=unname(FIML_as))
    ret
}
```

Using this definition the final object returned by `runSimulation()` will provide suitable `NA` placeholders (where appropriate), otherwise if different names were returned by the `Analyse2()` definition for continuous indicators the results will be presented as though `mirt` was never used for the continuous indicator conditions controlled by the `Design` object. 

